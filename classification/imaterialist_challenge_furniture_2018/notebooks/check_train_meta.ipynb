{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check meta-model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, Path(\".\").absolute().parent.as_posix())\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from common.dataset import FilesFromCsvDataset, TransformedDataset\n",
    "from common.meta import get_metafeatures, get_imsize_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(rc={'figure.figsize':(12, 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topk_df(df, k):\n",
    "    topk_values = np.argsort(df.values, axis=1)[:, -k:]\n",
    "    cols = [\"top_{}\".format(k - i) for i in range(k)]\n",
    "    topk_df = pd.DataFrame(topk_values, index=df.index, columns=cols)\n",
    "    return topk_df\n",
    "\n",
    "\n",
    "def get_metafeatures(prediction_files):\n",
    "    dfs = [pd.read_csv(f, index_col='id') for f in prediction_files]\n",
    "    for i, df in enumerate(dfs):\n",
    "        df.columns = [\"f{}_{}\".format(i, c) for c in df.columns]\n",
    "    meta_features = pd.concat([df for df in dfs], axis=1)\n",
    "    return meta_features\n",
    "\n",
    "\n",
    "def get_topk_metafeatures(prediction_files, k=5):\n",
    "    dfs = [pd.read_csv(f, index_col='id') for f in prediction_files]\n",
    "    dfs = [create_topk_df(df, k=k) for df in dfs]\n",
    "    for i, df in enumerate(dfs):\n",
    "        df.columns = [\"f{}_{}\".format(i, c) for c in df.columns]\n",
    "    meta_features = pd.concat([df for df in dfs], axis=1)\n",
    "    return meta_features, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features_path = Path(\"../output\")\n",
    "meta_features_list = [\n",
    "    meta_features_path / \"val_probas_inceptionresnetv2_350_resized_crop\" / \"20180428_1622\" / \"probas.csv\",\n",
    "    meta_features_path / \"val_probas_inceptionv4_350_resized_crop\" / \"20180428_1633\" / \"probas.csv\",\n",
    "    meta_features_path / \"val_probas_nasnetalarge_350_resized_crop\" / \"20180428_1654\" / \"probas.csv\",\n",
    "]\n",
    "# meta_features, dfs = get_topk_metafeatures(meta_features_list)\n",
    "meta_features = get_metafeatures(meta_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features.loc[6, ['f0_c124', 'f0_c46', 'f1_c124', 'f1_c46']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_c0</th>\n",
       "      <th>f0_c1</th>\n",
       "      <th>f0_c2</th>\n",
       "      <th>f0_c3</th>\n",
       "      <th>f0_c4</th>\n",
       "      <th>f0_c5</th>\n",
       "      <th>f0_c6</th>\n",
       "      <th>f0_c7</th>\n",
       "      <th>f0_c8</th>\n",
       "      <th>f0_c9</th>\n",
       "      <th>...</th>\n",
       "      <th>f2_c118</th>\n",
       "      <th>f2_c119</th>\n",
       "      <th>f2_c120</th>\n",
       "      <th>f2_c121</th>\n",
       "      <th>f2_c122</th>\n",
       "      <th>f2_c123</th>\n",
       "      <th>f2_c124</th>\n",
       "      <th>f2_c125</th>\n",
       "      <th>f2_c126</th>\n",
       "      <th>f2_c127</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>1.373452e-11</td>\n",
       "      <td>1.510409e-10</td>\n",
       "      <td>1.260431e-12</td>\n",
       "      <td>4.921817e-12</td>\n",
       "      <td>1.109817e-10</td>\n",
       "      <td>2.236590e-12</td>\n",
       "      <td>5.073530e-11</td>\n",
       "      <td>2.922072e-12</td>\n",
       "      <td>2.468959e-12</td>\n",
       "      <td>5.981444e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.210329e-07</td>\n",
       "      <td>8.096192e-08</td>\n",
       "      <td>1.443976e-07</td>\n",
       "      <td>2.385026e-08</td>\n",
       "      <td>7.237251e-08</td>\n",
       "      <td>9.203653e-08</td>\n",
       "      <td>2.834459e-08</td>\n",
       "      <td>3.299012e-07</td>\n",
       "      <td>4.945206e-07</td>\n",
       "      <td>1.290316e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>6.708128e-07</td>\n",
       "      <td>5.170703e-07</td>\n",
       "      <td>1.846702e-07</td>\n",
       "      <td>4.019679e-07</td>\n",
       "      <td>2.481107e-07</td>\n",
       "      <td>3.374197e-07</td>\n",
       "      <td>2.376433e-06</td>\n",
       "      <td>9.245439e-07</td>\n",
       "      <td>4.313464e-03</td>\n",
       "      <td>3.201822e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.495173e-06</td>\n",
       "      <td>6.100723e-06</td>\n",
       "      <td>2.764779e-05</td>\n",
       "      <td>3.801815e-06</td>\n",
       "      <td>5.896711e-04</td>\n",
       "      <td>5.913841e-06</td>\n",
       "      <td>2.201900e-06</td>\n",
       "      <td>1.681049e-05</td>\n",
       "      <td>4.249565e-06</td>\n",
       "      <td>2.703849e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1.588944e-07</td>\n",
       "      <td>3.460540e-06</td>\n",
       "      <td>1.504418e-05</td>\n",
       "      <td>3.487897e-06</td>\n",
       "      <td>3.223231e-08</td>\n",
       "      <td>1.037788e-06</td>\n",
       "      <td>5.816736e-07</td>\n",
       "      <td>1.317494e-08</td>\n",
       "      <td>5.965195e-07</td>\n",
       "      <td>3.312266e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.882467e-01</td>\n",
       "      <td>3.446758e-05</td>\n",
       "      <td>8.426102e-06</td>\n",
       "      <td>5.871575e-06</td>\n",
       "      <td>4.653336e-06</td>\n",
       "      <td>1.017057e-05</td>\n",
       "      <td>5.020957e-06</td>\n",
       "      <td>7.487863e-06</td>\n",
       "      <td>3.937877e-05</td>\n",
       "      <td>6.771946e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>5.284062e-11</td>\n",
       "      <td>1.166769e-08</td>\n",
       "      <td>2.623240e-11</td>\n",
       "      <td>6.023646e-10</td>\n",
       "      <td>3.024778e-07</td>\n",
       "      <td>3.700055e-10</td>\n",
       "      <td>2.080192e-10</td>\n",
       "      <td>8.870108e-11</td>\n",
       "      <td>1.285723e-10</td>\n",
       "      <td>1.011352e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152033e-08</td>\n",
       "      <td>6.093003e-07</td>\n",
       "      <td>1.255923e-07</td>\n",
       "      <td>2.138172e-08</td>\n",
       "      <td>3.975764e-08</td>\n",
       "      <td>1.062255e-07</td>\n",
       "      <td>1.688745e-06</td>\n",
       "      <td>5.186873e-07</td>\n",
       "      <td>1.641713e-06</td>\n",
       "      <td>2.073703e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1.060053e-04</td>\n",
       "      <td>2.394826e-07</td>\n",
       "      <td>4.066390e-06</td>\n",
       "      <td>1.615211e-05</td>\n",
       "      <td>1.085549e-07</td>\n",
       "      <td>6.640157e-05</td>\n",
       "      <td>1.039728e-06</td>\n",
       "      <td>5.748253e-08</td>\n",
       "      <td>1.454809e-06</td>\n",
       "      <td>2.930471e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.788781e-04</td>\n",
       "      <td>6.484089e-02</td>\n",
       "      <td>4.440381e-06</td>\n",
       "      <td>1.617641e-06</td>\n",
       "      <td>3.059961e-06</td>\n",
       "      <td>2.804265e-06</td>\n",
       "      <td>1.500740e-05</td>\n",
       "      <td>4.778179e-06</td>\n",
       "      <td>5.958621e-06</td>\n",
       "      <td>8.954229e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0_c0         f0_c1         f0_c2         f0_c3         f0_c4  \\\n",
       "id                                                                           \n",
       "6302  1.373452e-11  1.510409e-10  1.260431e-12  4.921817e-12  1.109817e-10   \n",
       "3349  6.708128e-07  5.170703e-07  1.846702e-07  4.019679e-07  2.481107e-07   \n",
       "484   1.588944e-07  3.460540e-06  1.504418e-05  3.487897e-06  3.223231e-08   \n",
       "2677  5.284062e-11  1.166769e-08  2.623240e-11  6.023646e-10  3.024778e-07   \n",
       "1517  1.060053e-04  2.394826e-07  4.066390e-06  1.615211e-05  1.085549e-07   \n",
       "\n",
       "             f0_c5         f0_c6         f0_c7         f0_c8         f0_c9  \\\n",
       "id                                                                           \n",
       "6302  2.236590e-12  5.073530e-11  2.922072e-12  2.468959e-12  5.981444e-12   \n",
       "3349  3.374197e-07  2.376433e-06  9.245439e-07  4.313464e-03  3.201822e-07   \n",
       "484   1.037788e-06  5.816736e-07  1.317494e-08  5.965195e-07  3.312266e-07   \n",
       "2677  3.700055e-10  2.080192e-10  8.870108e-11  1.285723e-10  1.011352e-10   \n",
       "1517  6.640157e-05  1.039728e-06  5.748253e-08  1.454809e-06  2.930471e-05   \n",
       "\n",
       "          ...            f2_c118       f2_c119       f2_c120       f2_c121  \\\n",
       "id        ...                                                                \n",
       "6302      ...       1.210329e-07  8.096192e-08  1.443976e-07  2.385026e-08   \n",
       "3349      ...       4.495173e-06  6.100723e-06  2.764779e-05  3.801815e-06   \n",
       "484       ...       9.882467e-01  3.446758e-05  8.426102e-06  5.871575e-06   \n",
       "2677      ...       2.152033e-08  6.093003e-07  1.255923e-07  2.138172e-08   \n",
       "1517      ...       4.788781e-04  6.484089e-02  4.440381e-06  1.617641e-06   \n",
       "\n",
       "           f2_c122       f2_c123       f2_c124       f2_c125       f2_c126  \\\n",
       "id                                                                           \n",
       "6302  7.237251e-08  9.203653e-08  2.834459e-08  3.299012e-07  4.945206e-07   \n",
       "3349  5.896711e-04  5.913841e-06  2.201900e-06  1.681049e-05  4.249565e-06   \n",
       "484   4.653336e-06  1.017057e-05  5.020957e-06  7.487863e-06  3.937877e-05   \n",
       "2677  3.975764e-08  1.062255e-07  1.688745e-06  5.186873e-07  1.641713e-06   \n",
       "1517  3.059961e-06  2.804265e-06  1.500740e-05  4.778179e-06  5.958621e-06   \n",
       "\n",
       "           f2_c127  \n",
       "id                  \n",
       "6302  1.290316e-07  \n",
       "3349  2.703849e-06  \n",
       "484   6.771946e-06  \n",
       "2677  2.073703e-07  \n",
       "1517  8.954229e-05  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 384)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FilesFromCsvDataset(\"../output/filtered_val_dataset.csv\")\n",
    "dataset = TransformedDataset(dataset,\n",
    "                             transforms=lambda x: (x, Image.open(x).size),\n",
    "                             target_transforms=lambda l: l - 1)\n",
    "df_imsize_targets = get_imsize_and_targets(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6291, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>target</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>800</td>\n",
       "      <td>47</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>550</td>\n",
       "      <td>78</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>800</td>\n",
       "      <td>118</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>480</td>\n",
       "      <td>26</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>800</td>\n",
       "      <td>21</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      height  target  width\n",
       "6302     800      47    800\n",
       "3349     550      78    730\n",
       "484      800     118    800\n",
       "2677     480      26    640\n",
       "1517     800      21    800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_imsize_targets.shape)\n",
    "df_imsize_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(df, col_name):\n",
    "    m1 = df[col_name].min()\n",
    "    m2 = df[col_name].max()\n",
    "    df.loc[:, col_name] = (df[col_name] - m1) / (m2 - m1 + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imsize_targets.loc[:, 'size'] = df_imsize_targets['width'] * df_imsize_targets['height']\n",
    "\n",
    "min_max_scale(df_imsize_targets, 'width')\n",
    "min_max_scale(df_imsize_targets, 'height')\n",
    "min_max_scale(df_imsize_targets, 'size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([meta_features, df_imsize_targets[['width', 'height', 'size']]], axis=1)\n",
    "X.dropna(inplace=True)\n",
    "y = df_imsize_targets.loc[X.index, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6291, 387), (6291,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_c0</th>\n",
       "      <th>f0_c1</th>\n",
       "      <th>f0_c2</th>\n",
       "      <th>f0_c3</th>\n",
       "      <th>f0_c4</th>\n",
       "      <th>f0_c5</th>\n",
       "      <th>f0_c6</th>\n",
       "      <th>f0_c7</th>\n",
       "      <th>f0_c8</th>\n",
       "      <th>f0_c9</th>\n",
       "      <th>...</th>\n",
       "      <th>f2_c121</th>\n",
       "      <th>f2_c122</th>\n",
       "      <th>f2_c123</th>\n",
       "      <th>f2_c124</th>\n",
       "      <th>f2_c125</th>\n",
       "      <th>f2_c126</th>\n",
       "      <th>f2_c127</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.786763e-10</td>\n",
       "      <td>2.216359e-09</td>\n",
       "      <td>3.354208e-11</td>\n",
       "      <td>5.480898e-09</td>\n",
       "      <td>1.016345e-10</td>\n",
       "      <td>2.880471e-09</td>\n",
       "      <td>5.597683e-10</td>\n",
       "      <td>1.103374e-08</td>\n",
       "      <td>3.588944e-11</td>\n",
       "      <td>3.318691e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248070e-08</td>\n",
       "      <td>1.542437e-07</td>\n",
       "      <td>1.546837e-07</td>\n",
       "      <td>2.476480e-06</td>\n",
       "      <td>1.771896e-07</td>\n",
       "      <td>3.419645e-07</td>\n",
       "      <td>3.491577e-08</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.454174e-06</td>\n",
       "      <td>4.968147e-09</td>\n",
       "      <td>1.728579e-04</td>\n",
       "      <td>1.411724e-04</td>\n",
       "      <td>9.133302e-09</td>\n",
       "      <td>1.432796e-06</td>\n",
       "      <td>1.634426e-08</td>\n",
       "      <td>7.527779e-06</td>\n",
       "      <td>1.150549e-08</td>\n",
       "      <td>1.903884e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.956465e-05</td>\n",
       "      <td>4.131234e-06</td>\n",
       "      <td>1.263950e-05</td>\n",
       "      <td>3.168242e-05</td>\n",
       "      <td>6.963891e-04</td>\n",
       "      <td>7.767742e-06</td>\n",
       "      <td>5.908821e-05</td>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.088576</td>\n",
       "      <td>0.014782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.776277e-09</td>\n",
       "      <td>4.009195e-08</td>\n",
       "      <td>8.143656e-09</td>\n",
       "      <td>4.890069e-09</td>\n",
       "      <td>1.291318e-07</td>\n",
       "      <td>9.818061e-09</td>\n",
       "      <td>3.529312e-07</td>\n",
       "      <td>2.192131e-08</td>\n",
       "      <td>1.592583e-07</td>\n",
       "      <td>7.115647e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.951818e-07</td>\n",
       "      <td>3.182044e-07</td>\n",
       "      <td>5.872605e-05</td>\n",
       "      <td>2.711008e-07</td>\n",
       "      <td>2.351123e-06</td>\n",
       "      <td>1.549696e-07</td>\n",
       "      <td>7.264244e-07</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.005999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.465966e-08</td>\n",
       "      <td>9.050931e-09</td>\n",
       "      <td>4.340031e-09</td>\n",
       "      <td>1.269720e-03</td>\n",
       "      <td>9.529219e-09</td>\n",
       "      <td>4.225530e-09</td>\n",
       "      <td>1.333823e-08</td>\n",
       "      <td>5.796793e-04</td>\n",
       "      <td>2.795894e-09</td>\n",
       "      <td>1.915915e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.195381e-06</td>\n",
       "      <td>2.326123e-06</td>\n",
       "      <td>1.075147e-05</td>\n",
       "      <td>7.188110e-06</td>\n",
       "      <td>9.196233e-01</td>\n",
       "      <td>4.219503e-06</td>\n",
       "      <td>3.570874e-06</td>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.250429e-07</td>\n",
       "      <td>2.871629e-11</td>\n",
       "      <td>2.409671e-09</td>\n",
       "      <td>1.104301e-05</td>\n",
       "      <td>2.534062e-10</td>\n",
       "      <td>3.698222e-07</td>\n",
       "      <td>1.303015e-09</td>\n",
       "      <td>5.900128e-08</td>\n",
       "      <td>1.484111e-10</td>\n",
       "      <td>1.620004e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.987777e-09</td>\n",
       "      <td>2.220414e-08</td>\n",
       "      <td>3.893851e-08</td>\n",
       "      <td>1.038806e-08</td>\n",
       "      <td>1.222228e-08</td>\n",
       "      <td>9.131732e-09</td>\n",
       "      <td>4.092041e-08</td>\n",
       "      <td>0.093815</td>\n",
       "      <td>0.097614</td>\n",
       "      <td>0.017097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0_c0         f0_c1         f0_c2         f0_c3         f0_c4  \\\n",
       "1  1.786763e-10  2.216359e-09  3.354208e-11  5.480898e-09  1.016345e-10   \n",
       "2  1.454174e-06  4.968147e-09  1.728579e-04  1.411724e-04  9.133302e-09   \n",
       "3  7.776277e-09  4.009195e-08  8.143656e-09  4.890069e-09  1.291318e-07   \n",
       "4  9.465966e-08  9.050931e-09  4.340031e-09  1.269720e-03  9.529219e-09   \n",
       "5  1.250429e-07  2.871629e-11  2.409671e-09  1.104301e-05  2.534062e-10   \n",
       "\n",
       "          f0_c5         f0_c6         f0_c7         f0_c8         f0_c9  \\\n",
       "1  2.880471e-09  5.597683e-10  1.103374e-08  3.588944e-11  3.318691e-09   \n",
       "2  1.432796e-06  1.634426e-08  7.527779e-06  1.150549e-08  1.903884e-09   \n",
       "3  9.818061e-09  3.529312e-07  2.192131e-08  1.592583e-07  7.115647e-08   \n",
       "4  4.225530e-09  1.333823e-08  5.796793e-04  2.795894e-09  1.915915e-10   \n",
       "5  3.698222e-07  1.303015e-09  5.900128e-08  1.484111e-10  1.620004e-09   \n",
       "\n",
       "     ...          f2_c121       f2_c122       f2_c123       f2_c124  \\\n",
       "1    ...     4.248070e-08  1.542437e-07  1.546837e-07  2.476480e-06   \n",
       "2    ...     5.956465e-05  4.131234e-06  1.263950e-05  3.168242e-05   \n",
       "3    ...     1.951818e-07  3.182044e-07  5.872605e-05  2.711008e-07   \n",
       "4    ...     3.195381e-06  2.326123e-06  1.075147e-05  7.188110e-06   \n",
       "5    ...     5.987777e-09  2.220414e-08  3.893851e-08  1.038806e-08   \n",
       "\n",
       "        f2_c125       f2_c126       f2_c127     width    height      size  \n",
       "1  1.771896e-07  3.419645e-07  3.491577e-08  0.004170  0.004338  0.000390  \n",
       "2  6.963891e-04  7.767742e-06  5.908821e-05  0.085129  0.088576  0.014782  \n",
       "3  2.351123e-06  1.549696e-07  7.264244e-07  0.067755  0.027657  0.005999  \n",
       "4  9.196233e-01  4.219503e-06  3.570874e-06  0.085129  0.043565  0.009204  \n",
       "5  1.222228e-08  9.131732e-09  4.092041e-08  0.093815  0.097614  0.017097  \n",
       "\n",
       "[5 rows x 387 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     37\n",
       "2     62\n",
       "3     32\n",
       "4    125\n",
       "5     17\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features.loc[6302, :], df_imsize_targets.loc[6302, 'width'], y.loc[6302]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(pd.concat([X, y], axis=1).corr(), linewidths=.5);\n",
    "# plt.yticks(rotation=0);\n",
    "# plt.xticks(rotation=30);\n",
    "# sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifed = {1: {'recall': 0.84, 'wrong_classes': [(87, 4)]},\n",
    " 3: {'recall': 0.5625, 'wrong_classes': [(2, 7), (28, 5)]},\n",
    " 14: {'recall': 0.3, 'wrong_classes': [(3, 4), (28, 5), (62, 8), (125, 6)]},\n",
    " 18: {'recall': 0.66, 'wrong_classes': [(127, 7)]},\n",
    " 21: {'recall': 0.7872340425531915, 'wrong_classes': [(16, 4)]},\n",
    " 22: {'recall': 0.7551020408163265, 'wrong_classes': [(62, 6)]},\n",
    " 26: {'recall': 0.6938775510204082, 'wrong_classes': [(111, 9)]},\n",
    " 27: {'recall': 0.8979591836734694, 'wrong_classes': [(23, 4)]},\n",
    " 30: {'recall': 0.7916666666666666, 'wrong_classes': [(69, 6)]},\n",
    " 34: {'recall': 0.7916666666666666, 'wrong_classes': [(12, 4), (69, 4)]},\n",
    " 38: {'recall': 0.68, 'wrong_classes': [(86, 11), (108, 5)]},\n",
    " 48: {'recall': 0.7346938775510204, 'wrong_classes': [(124, 5)]},\n",
    " 49: {'recall': 0.6530612244897959, 'wrong_classes': [(19, 4), (53, 12)]},\n",
    " 50: {'recall': 0.75, 'wrong_classes': [(52, 4)]},\n",
    " 53: {'recall': 0.7755102040816326, 'wrong_classes': [(19, 4)]},\n",
    " 57: {'recall': 0.8775510204081632, 'wrong_classes': [(2, 4)]},\n",
    " 58: {'recall': 0.86, 'wrong_classes': [(41, 4)]},\n",
    " 62: {'recall': 0.3, 'wrong_classes': [(14, 6), (22, 5), (25, 8), (28, 9)]},\n",
    " 65: {'recall': 0.48, 'wrong_classes': [(31, 5), (39, 7), (56, 6), (101, 4)]},\n",
    " 66: {'recall': 0.8541666666666666, 'wrong_classes': [(112, 5)]},\n",
    " 69: {'recall': 0.7959183673469388, 'wrong_classes': [(116, 4)]},\n",
    " 81: {'recall': 0.88, 'wrong_classes': [(126, 4)]},\n",
    " 86: {'recall': 0.9, 'wrong_classes': [(38, 4)]},\n",
    " 87: {'recall': 0.74, 'wrong_classes': [(1, 4), (53, 5)]},\n",
    " 96: {'recall': 0.8, 'wrong_classes': [(88, 4)]},\n",
    " 99: {'recall': 0.7959183673469388, 'wrong_classes': [(19, 7)]},\n",
    " 104: {'recall': 0.6875, 'wrong_classes': [(59, 12)]},\n",
    " 107: {'recall': 0.86, 'wrong_classes': [(4, 4)]},\n",
    " 108: {'recall': 0.875, 'wrong_classes': [(38, 6)]},\n",
    " 111: {'recall': 0.8, 'wrong_classes': [(26, 7)]},\n",
    " 112: {'recall': 0.9, 'wrong_classes': [(66, 4)]},\n",
    " 113: {'recall': 0.78, 'wrong_classes': [(81, 8)]},\n",
    " 114: {'recall': 0.8163265306122449, 'wrong_classes': [(120, 5)]},\n",
    " 123: {'recall': 0.6122448979591837, 'wrong_classes': [(64, 17)]},\n",
    " 126: {'recall': 0.8125, 'wrong_classes': [(81, 7)]},\n",
    " 127: {'recall': 0.8125, 'wrong_classes': [(18, 5)]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-features learning, 128 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xy = pd.concat([X, y], axis=1)\n",
    "# meta_features.loc[53, 'f0_c41']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class K (0, ..., 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- class :  14\n",
      "{'C': 6.951927961775605, 'penalty': 'l2'} -0.024665787591909554\n",
      "Recall: 0.38461538461538464 vs 0.3076923076923077\n",
      "Precision: 0.7142857142857143 vs 0.6666666666666666\n",
      "Accuracy: 0.9936427209154481 vs 0.993006993006993\n",
      "-- class :  62\n",
      "{'C': 4.281332398719393, 'penalty': 'l2'} -0.026060559781892072\n",
      "Recall: 0.23076923076923078 vs 0.38461538461538464\n",
      "Precision: 1.0 vs 0.625\n",
      "Accuracy: 0.9936427209154481 vs 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "n_classes = 128\n",
    "seed = 555\n",
    "n = len(meta_features_list)\n",
    "\n",
    "\n",
    "for class_index in [14, 62]:\n",
    "\n",
    "    print(\"-- class : \", class_index)    \n",
    "    cols = ['f{}_c{}'.format(i, class_index) for i in range(n)] \n",
    "    for c, _ in misclassifed[class_index]['wrong_classes']:        \n",
    "        cols += ['f{}_c{}'.format(i, c) for i in range(n)] \n",
    "    cols += ['size', 'width', 'height']\n",
    "    _X = X[cols].values\n",
    "#     _X = X.values\n",
    "    _y = (y == class_index).values.astype(np.int)\n",
    "\n",
    "    # clip probabilities:\n",
    "    # _X = np.clip(_X, 0.00001, 0.99999)\n",
    "    \n",
    "    splt = StratifiedShuffleSplit(n_splits=7, test_size=0.25, random_state=seed)\n",
    "    train_index, test_index = next(splt.split(_X, _y))\n",
    "\n",
    "    _X_train = _X[train_index, :]\n",
    "    _X_test = _X[test_index, :]\n",
    "    _y_train = _y[train_index]\n",
    "    _y_test = _y[test_index]\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    log_reg = LogisticRegression(random_state=seed)\n",
    "    params = {\n",
    "        \"C\": np.logspace(0, 4, 20),\n",
    "        \"penalty\": [\"l2\", ],\n",
    "    }\n",
    "    gs = GridSearchCV(log_reg, params, scoring=\"neg_log_loss\", cv=cv, n_jobs=10)    \n",
    "    gs.fit(_X_train, _y_train)\n",
    "    print(gs.best_params_, gs.best_score_)\n",
    "    # _y_probas = gs.best_estimator_.predict_proba(_X_test)\n",
    "    _y_pred = gs.best_estimator_.predict(_X_test)\n",
    "    \n",
    "    _y_pred_base = (_X_test[:, :n].mean(axis=1) > 0.5).astype(np.int)\n",
    "    \n",
    "    print(\"Recall: {} vs {}\".format(recall_score(_y_test, _y_pred), recall_score(_y_test, _y_pred_base)))\n",
    "    print(\"Precision: {} vs {}\".format(precision_score(_y_test, _y_pred), precision_score(_y_test, _y_pred_base)))\n",
    "    print(\"Accuracy: {} vs {}\".format(accuracy_score(_y_test, _y_pred), accuracy_score(_y_test, _y_pred_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_index = 62\n",
    "_y = (y == class_index).values.astype(np.int)\n",
    "cols = ['f{}_c{}'.format(i, class_index) for i in range(n)]\n",
    "_y_pred_base = (_X[:, np.where(X.columns.isin(cols))[0]].mean(axis=1) > 0.5).astype(np.int)\n",
    "recall_score(_y, _y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beatiful_coef(coefs, feature_names):\n",
    "    return pd.DataFrame(coefs.transpose(), index=feature_names, columns=['coef']).sort_values('coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beatiful_coef(gs.best_estimator_.coef_, feature_names=X[cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- class :  14\n",
      "{'learning_rate': 0.01, 'max_depth': 4} -0.21471614459463984\n",
      "Recall: 0.5384615384615384 vs 0.3076923076923077\n",
      "Precision: 0.5384615384615384 vs 0.6666666666666666\n",
      "Accuracy: 0.9923712650985378 vs 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "n_classes = 128\n",
    "seed = 555\n",
    "n = len(meta_features_list)\n",
    "\n",
    "\n",
    "for class_index in [14,]:\n",
    "\n",
    "    print(\"-- class : \", class_index)\n",
    "    \n",
    "    cols = ['f{}_c{}'.format(i, class_index) for i in range(n)] \n",
    "    for c, _ in misclassifed[class_index]['wrong_classes']:        \n",
    "        cols += ['f{}_c{}'.format(i, c) for i in range(n)] \n",
    "    cols += ['size', 'width', 'height']\n",
    "    _X = X[cols].values\n",
    "    _y = (y == class_index).values.astype(np.int)\n",
    "\n",
    "    # clip probabilities:\n",
    "    # _X = np.clip(_X, 0.00001, 0.99999)\n",
    "    \n",
    "    splt = StratifiedShuffleSplit(n_splits=7, test_size=0.25, random_state=seed)\n",
    "    train_index, test_index = next(splt.split(_X, _y))\n",
    "\n",
    "    _X_train = _X[train_index, :]\n",
    "    _X_test = _X[test_index, :]\n",
    "    _y_train = _y[train_index]\n",
    "    _y_test = _y[test_index]\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    clf = XGBClassifier(random_state=seed)\n",
    "    params = {\n",
    "        \"max_depth\": [3, 4, 5],\n",
    "        \"learning_rate\": [0.01, 0.003, 0.001]\n",
    "    }\n",
    "    gs = GridSearchCV(clf, params, scoring=\"neg_log_loss\", cv=cv, n_jobs=10)    \n",
    "    gs.fit(_X_train, _y_train)\n",
    "    print(gs.best_params_, gs.best_score_) \n",
    "    _y_probas = gs.best_estimator_.predict_proba(_X_test)\n",
    "#     _y_pred = gs.best_estimator_.predict(_X_test)\n",
    "    _y_pred = (_y_probas[:, 1] > 0.5).astype(np.int)\n",
    "    \n",
    "    _y_pred_base = (_X_test[:, :n].mean(axis=1) > 0.5).astype(np.int)\n",
    "\n",
    "    print(\"Recall: {} vs {}\".format(recall_score(_y_test, _y_pred), recall_score(_y_test, _y_pred_base)))\n",
    "    print(\"Precision: {} vs {}\".format(precision_score(_y_test, _y_pred), precision_score(_y_test, _y_pred_base)))\n",
    "    print(\"Accuracy: {} vs {}\".format(accuracy_score(_y_test, _y_pred), accuracy_score(_y_test, _y_pred_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f0_c14: 0.1505376398563385',\n",
       " 'f1_c14: 0.0',\n",
       " 'f2_c14: 0.24946236610412598',\n",
       " 'f0_c3: 0.009677419438958168',\n",
       " 'f1_c3: 0.0010752688394859433',\n",
       " 'f2_c3: 0.08602150529623032',\n",
       " 'f0_c28: 0.10215053707361221',\n",
       " 'f1_c28: 0.03548387065529823',\n",
       " 'f2_c28: 0.07741935551166534',\n",
       " 'f0_c62: 0.0010752688394859433',\n",
       " 'f1_c62: 0.017204301431775093',\n",
       " 'f2_c62: 0.0',\n",
       " 'f0_c125: 0.07956989109516144',\n",
       " 'f1_c125: 0.13548387587070465',\n",
       " 'f2_c125: 0.04838709533214569',\n",
       " 'size: 0.0',\n",
       " 'width: 0.004301075357943773',\n",
       " 'height: 0.0021505376789718866']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{}: {}\".format(c, v) for c, v in zip(X[cols].columns, best_model.feature_importances_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15053764, 0.        , 0.24946237, 0.00967742, 0.00107527,\n",
       "       0.08602151, 0.10215054, 0.03548387, 0.07741936, 0.00107527,\n",
       "       0.0172043 , 0.        , 0.07956989, 0.13548388, 0.0483871 ,\n",
       "       0.        , 0.00430108, 0.00215054], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = cat.Pool(_X_train, label=_y_train)\n",
    "cat_test = cat.Pool(_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 10,\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"eval_metric\": \"Accuracy\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    \"depth\": 4,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"od_wait\": 50,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0571204\ttest: 0.0379284\tbest: 0.0379284 (0)\ttotal: 12.2s\tremaining: 1m 49s\n",
      "1:\tlearn: 0.1171925\ttest: 0.0910784\tbest: 0.0910784 (1)\ttotal: 24.8s\tremaining: 1m 39s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-c6c1ef4c4d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, verbose, verbose_eval, plot)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_results = cat.cv(cat_train, params=params, nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:52: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0758574\ttotal: 11.8s\tremaining: 1m 34s\n",
      "1:\tlearn: 0.1301385\ttotal: 25.5s\tremaining: 1m 29s\n",
      "2:\tlearn: 0.1739723\ttotal: 40.1s\tremaining: 1m 20s\n",
      "3:\tlearn: 0.2784465\ttotal: 53.6s\tremaining: 1m 7s\n",
      "4:\tlearn: 0.3445378\ttotal: 1m 6s\tremaining: 53.5s\n",
      "5:\tlearn: 0.3967749\ttotal: 1m 20s\tremaining: 40.1s\n",
      "6:\tlearn: 0.4047241\ttotal: 1m 33s\tremaining: 26.7s\n",
      "7:\tlearn: 0.4397002\ttotal: 1m 46s\tremaining: 13.3s\n",
      "8:\tlearn: 0.4635476\ttotal: 1m 59s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "best_iterations = np.argmax(cv_results['test-%s-mean' % params['eval_metric']])\n",
    "params['iterations'] = best_iterations + 1\n",
    "\n",
    "cat_model = cat.train(params=params, pool=cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatboostError",
     "evalue": "Data cat_features in predict()=[] are not equal data cat_features in fit()=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatboostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-c1ffa86ea282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \"\"\"\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_staged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cat_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cat_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cat_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data cat_features in predict()={} are not equal data cat_features in fit()={}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cat_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cat_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCatboostError\u001b[0m: Data cat_features in predict()=[] are not equal data cat_features in fit()=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]."
     ]
    }
   ],
   "source": [
    "_y_pred = cat_model.predict(cat_test, prediction_type=\"Class\").ravel().astype(np.int)\n",
    "accuracy_score(_y_test, _y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 116,  15, ..., 116,  54, 111])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65, 52, 38, ..., 40, 19, 65])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(_X_train, label=_y_train)\n",
    "xgb_test = xgb.DMatrix(_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.01,\n",
    "    \"gamma\": 0.1,\n",
    "    \"max_depth\": 4,\n",
    "    \"num_class\": 128,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"seed\": 1272,     \n",
    "    \"subsample\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:4.84599+3.4308e-05\ttest-mlogloss:4.84655+0.000121354\n",
      "[1]\ttrain-mlogloss:4.83983+0.000200851\ttest-mlogloss:4.84086+0.000270838\n",
      "[2]\ttrain-mlogloss:4.83364+0.000273281\ttest-mlogloss:4.8352+0.000393063\n",
      "[3]\ttrain-mlogloss:4.82739+0.000368472\ttest-mlogloss:4.82947+0.000549695\n",
      "[4]\ttrain-mlogloss:4.8214+0.000370113\ttest-mlogloss:4.82394+0.000565074\n",
      "[5]\ttrain-mlogloss:4.81526+0.000428553\ttest-mlogloss:4.81829+0.000607652\n",
      "[6]\ttrain-mlogloss:4.80916+0.000552534\ttest-mlogloss:4.8127+0.000656493\n",
      "[7]\ttrain-mlogloss:4.80295+0.000538376\ttest-mlogloss:4.80701+0.000668191\n",
      "[8]\ttrain-mlogloss:4.79685+0.000636949\ttest-mlogloss:4.8014+0.000741941\n",
      "[9]\ttrain-mlogloss:4.79066+0.000667106\ttest-mlogloss:4.79572+0.000763709\n",
      "[10]\ttrain-mlogloss:4.7845+0.000608217\ttest-mlogloss:4.79007+0.000752721\n",
      "[11]\ttrain-mlogloss:4.77844+0.000554622\ttest-mlogloss:4.78457+0.000704097\n",
      "[12]\ttrain-mlogloss:4.77237+0.000668272\ttest-mlogloss:4.77909+0.000686543\n",
      "[13]\ttrain-mlogloss:4.76641+0.000615831\ttest-mlogloss:4.77367+0.000753354\n",
      "[14]\ttrain-mlogloss:4.76019+0.000582336\ttest-mlogloss:4.76799+0.000737255\n",
      "[15]\ttrain-mlogloss:4.75413+0.00068809\ttest-mlogloss:4.76243+0.000781937\n",
      "[16]\ttrain-mlogloss:4.74794+0.000676562\ttest-mlogloss:4.75677+0.000807818\n",
      "[17]\ttrain-mlogloss:4.74183+0.000768941\ttest-mlogloss:4.75124+0.000836646\n",
      "[18]\ttrain-mlogloss:4.73564+0.000818654\ttest-mlogloss:4.74556+0.000873296\n",
      "[19]\ttrain-mlogloss:4.72964+0.000777783\ttest-mlogloss:4.74013+0.000844884\n",
      "[20]\ttrain-mlogloss:4.72335+0.000900365\ttest-mlogloss:4.73438+0.000919404\n",
      "[21]\ttrain-mlogloss:4.71738+0.000936302\ttest-mlogloss:4.72896+0.000892658\n",
      "[22]\ttrain-mlogloss:4.71128+0.000924392\ttest-mlogloss:4.72336+0.000961334\n",
      "[23]\ttrain-mlogloss:4.7052+0.00102086\ttest-mlogloss:4.71776+0.00113044\n",
      "[24]\ttrain-mlogloss:4.69902+0.000957502\ttest-mlogloss:4.71214+0.00119042\n",
      "[25]\ttrain-mlogloss:4.69274+0.000891059\ttest-mlogloss:4.70635+0.00115751\n",
      "[26]\ttrain-mlogloss:4.68662+0.000838288\ttest-mlogloss:4.70073+0.00120573\n",
      "[27]\ttrain-mlogloss:4.68044+0.000860223\ttest-mlogloss:4.69506+0.00117722\n",
      "[28]\ttrain-mlogloss:4.67432+0.000945772\ttest-mlogloss:4.68949+0.00121377\n",
      "[29]\ttrain-mlogloss:4.66827+0.000946321\ttest-mlogloss:4.68398+0.00128798\n",
      "[30]\ttrain-mlogloss:4.6621+0.00103886\ttest-mlogloss:4.67828+0.00118556\n",
      "[31]\ttrain-mlogloss:4.65606+0.00111564\ttest-mlogloss:4.67277+0.00116114\n",
      "[32]\ttrain-mlogloss:4.65009+0.00128586\ttest-mlogloss:4.66735+0.00121132\n",
      "[33]\ttrain-mlogloss:4.64397+0.00129505\ttest-mlogloss:4.66174+0.00117479\n",
      "[34]\ttrain-mlogloss:4.63784+0.00143148\ttest-mlogloss:4.6561+0.00106416\n",
      "[35]\ttrain-mlogloss:4.63177+0.00143578\ttest-mlogloss:4.65053+0.00108707\n",
      "[36]\ttrain-mlogloss:4.62572+0.00143127\ttest-mlogloss:4.645+0.00127577\n",
      "[37]\ttrain-mlogloss:4.61954+0.00146004\ttest-mlogloss:4.63934+0.00131172\n",
      "[38]\ttrain-mlogloss:4.6135+0.00144635\ttest-mlogloss:4.63377+0.0012106\n",
      "[39]\ttrain-mlogloss:4.60741+0.00161652\ttest-mlogloss:4.62818+0.00125932\n",
      "[40]\ttrain-mlogloss:4.60142+0.00168712\ttest-mlogloss:4.62271+0.00133475\n",
      "[41]\ttrain-mlogloss:4.59537+0.00174335\ttest-mlogloss:4.61712+0.00133196\n",
      "[42]\ttrain-mlogloss:4.5894+0.00175805\ttest-mlogloss:4.61162+0.00132171\n",
      "[43]\ttrain-mlogloss:4.58333+0.00167554\ttest-mlogloss:4.6061+0.00142406\n",
      "[44]\ttrain-mlogloss:4.57733+0.00172886\ttest-mlogloss:4.60061+0.00147112\n",
      "[45]\ttrain-mlogloss:4.57137+0.00182842\ttest-mlogloss:4.59518+0.00163177\n",
      "[46]\ttrain-mlogloss:4.56536+0.00170084\ttest-mlogloss:4.58969+0.00170238\n",
      "[47]\ttrain-mlogloss:4.55934+0.00160953\ttest-mlogloss:4.58418+0.00183443\n",
      "[48]\ttrain-mlogloss:4.55331+0.00178312\ttest-mlogloss:4.57877+0.00188833\n",
      "[49]\ttrain-mlogloss:4.54728+0.00180811\ttest-mlogloss:4.57324+0.00192223\n",
      "[50]\ttrain-mlogloss:4.54118+0.00183499\ttest-mlogloss:4.56764+0.00195189\n",
      "[51]\ttrain-mlogloss:4.53512+0.00199666\ttest-mlogloss:4.56207+0.00201434\n",
      "[52]\ttrain-mlogloss:4.52914+0.00199205\ttest-mlogloss:4.55661+0.00206224\n",
      "[53]\ttrain-mlogloss:4.52316+0.00202069\ttest-mlogloss:4.55114+0.00225836\n",
      "[54]\ttrain-mlogloss:4.51706+0.0021021\ttest-mlogloss:4.54557+0.00227785\n",
      "[55]\ttrain-mlogloss:4.51097+0.0021733\ttest-mlogloss:4.54006+0.00225728\n",
      "[56]\ttrain-mlogloss:4.50505+0.00224574\ttest-mlogloss:4.53467+0.00240057\n",
      "[57]\ttrain-mlogloss:4.49916+0.00210775\ttest-mlogloss:4.52923+0.00254318\n",
      "[58]\ttrain-mlogloss:4.49309+0.00212168\ttest-mlogloss:4.52366+0.00248265\n",
      "[59]\ttrain-mlogloss:4.48716+0.00199501\ttest-mlogloss:4.51823+0.00270187\n",
      "[60]\ttrain-mlogloss:4.48111+0.00201751\ttest-mlogloss:4.51265+0.00268754\n",
      "[61]\ttrain-mlogloss:4.47516+0.00187613\ttest-mlogloss:4.50727+0.00268776\n",
      "[62]\ttrain-mlogloss:4.46915+0.00195616\ttest-mlogloss:4.50182+0.00265409\n",
      "[63]\ttrain-mlogloss:4.46316+0.00197067\ttest-mlogloss:4.49636+0.00275926\n",
      "[64]\ttrain-mlogloss:4.45707+0.00211484\ttest-mlogloss:4.4908+0.00284039\n",
      "[65]\ttrain-mlogloss:4.45113+0.00216211\ttest-mlogloss:4.48541+0.00288913\n",
      "[66]\ttrain-mlogloss:4.44515+0.00214525\ttest-mlogloss:4.47988+0.00298009\n",
      "[67]\ttrain-mlogloss:4.43921+0.00213915\ttest-mlogloss:4.47444+0.00289736\n",
      "[68]\ttrain-mlogloss:4.43334+0.00212663\ttest-mlogloss:4.46908+0.00296516\n",
      "[69]\ttrain-mlogloss:4.42741+0.00209179\ttest-mlogloss:4.46367+0.00319475\n",
      "[70]\ttrain-mlogloss:4.42152+0.00208162\ttest-mlogloss:4.45825+0.00328362\n",
      "[71]\ttrain-mlogloss:4.41557+0.00215109\ttest-mlogloss:4.45282+0.00330046\n",
      "[72]\ttrain-mlogloss:4.40963+0.00223672\ttest-mlogloss:4.44737+0.00332778\n",
      "[73]\ttrain-mlogloss:4.40379+0.00229476\ttest-mlogloss:4.44203+0.00341511\n",
      "[74]\ttrain-mlogloss:4.39801+0.00239556\ttest-mlogloss:4.43675+0.00354281\n",
      "[75]\ttrain-mlogloss:4.39212+0.00259573\ttest-mlogloss:4.43134+0.00363054\n",
      "[76]\ttrain-mlogloss:4.38612+0.0026157\ttest-mlogloss:4.42588+0.00367807\n",
      "[77]\ttrain-mlogloss:4.3802+0.00257913\ttest-mlogloss:4.42039+0.00374592\n",
      "[78]\ttrain-mlogloss:4.37426+0.00254185\ttest-mlogloss:4.41508+0.00396051\n",
      "[79]\ttrain-mlogloss:4.36835+0.00273805\ttest-mlogloss:4.40971+0.00392396\n",
      "[80]\ttrain-mlogloss:4.36247+0.00272331\ttest-mlogloss:4.40433+0.00387414\n",
      "[81]\ttrain-mlogloss:4.35667+0.00265427\ttest-mlogloss:4.399+0.00393545\n",
      "[82]\ttrain-mlogloss:4.35069+0.00270078\ttest-mlogloss:4.39354+0.0039331\n",
      "[83]\ttrain-mlogloss:4.34468+0.00271526\ttest-mlogloss:4.38807+0.00396406\n",
      "[84]\ttrain-mlogloss:4.33882+0.00261002\ttest-mlogloss:4.38269+0.00398854\n",
      "[85]\ttrain-mlogloss:4.333+0.00277164\ttest-mlogloss:4.37733+0.0041258\n",
      "[86]\ttrain-mlogloss:4.32714+0.0027442\ttest-mlogloss:4.37193+0.00431236\n",
      "[87]\ttrain-mlogloss:4.32122+0.00264355\ttest-mlogloss:4.3665+0.00426565\n",
      "[88]\ttrain-mlogloss:4.31524+0.00263658\ttest-mlogloss:4.36098+0.00431979\n",
      "[89]\ttrain-mlogloss:4.3093+0.00274657\ttest-mlogloss:4.35556+0.00433544\n",
      "[90]\ttrain-mlogloss:4.30348+0.00267001\ttest-mlogloss:4.35025+0.00427191\n",
      "[91]\ttrain-mlogloss:4.29763+0.00266626\ttest-mlogloss:4.34485+0.00431752\n",
      "[92]\ttrain-mlogloss:4.29185+0.00279431\ttest-mlogloss:4.33958+0.00418416\n",
      "[93]\ttrain-mlogloss:4.28586+0.00281811\ttest-mlogloss:4.33412+0.00417201\n",
      "[94]\ttrain-mlogloss:4.27999+0.00276863\ttest-mlogloss:4.32872+0.0042568\n",
      "[95]\ttrain-mlogloss:4.27407+0.00273118\ttest-mlogloss:4.32325+0.00430638\n",
      "[96]\ttrain-mlogloss:4.26829+0.00266833\ttest-mlogloss:4.31792+0.00433449\n",
      "[97]\ttrain-mlogloss:4.2624+0.0026509\ttest-mlogloss:4.31251+0.00433708\n",
      "[98]\ttrain-mlogloss:4.25647+0.00261592\ttest-mlogloss:4.30708+0.00433533\n",
      "[99]\ttrain-mlogloss:4.25051+0.00260218\ttest-mlogloss:4.30157+0.00438743\n",
      "[100]\ttrain-mlogloss:4.24467+0.00266505\ttest-mlogloss:4.29621+0.00434066\n",
      "[101]\ttrain-mlogloss:4.23877+0.0027782\ttest-mlogloss:4.29079+0.00450937\n",
      "[102]\ttrain-mlogloss:4.23297+0.00273609\ttest-mlogloss:4.28548+0.00456911\n",
      "[103]\ttrain-mlogloss:4.22709+0.00267363\ttest-mlogloss:4.28016+0.00465904\n",
      "[104]\ttrain-mlogloss:4.22129+0.00274882\ttest-mlogloss:4.27487+0.00467036\n",
      "[105]\ttrain-mlogloss:4.21549+0.00277536\ttest-mlogloss:4.26958+0.00469331\n",
      "[106]\ttrain-mlogloss:4.20972+0.00283047\ttest-mlogloss:4.26428+0.00458174\n",
      "[107]\ttrain-mlogloss:4.20392+0.00279899\ttest-mlogloss:4.25902+0.00472951\n",
      "[108]\ttrain-mlogloss:4.19815+0.00272605\ttest-mlogloss:4.25375+0.00480086\n",
      "[109]\ttrain-mlogloss:4.19238+0.0027931\ttest-mlogloss:4.24844+0.00490981\n",
      "[110]\ttrain-mlogloss:4.1866+0.00280516\ttest-mlogloss:4.24314+0.00496942\n",
      "[111]\ttrain-mlogloss:4.18071+0.00277077\ttest-mlogloss:4.2377+0.00497652\n",
      "[112]\ttrain-mlogloss:4.1749+0.0029014\ttest-mlogloss:4.23237+0.00493902\n",
      "[113]\ttrain-mlogloss:4.169+0.00294668\ttest-mlogloss:4.22695+0.00501784\n",
      "[114]\ttrain-mlogloss:4.16323+0.00298538\ttest-mlogloss:4.22167+0.0050771\n",
      "[115]\ttrain-mlogloss:4.15739+0.00297743\ttest-mlogloss:4.21626+0.00512155\n",
      "[116]\ttrain-mlogloss:4.15157+0.00306802\ttest-mlogloss:4.21095+0.00522981\n",
      "[117]\ttrain-mlogloss:4.14593+0.00307953\ttest-mlogloss:4.2058+0.00532574\n",
      "[118]\ttrain-mlogloss:4.14004+0.00307231\ttest-mlogloss:4.20042+0.0055406\n",
      "[119]\ttrain-mlogloss:4.13418+0.00315398\ttest-mlogloss:4.19506+0.0055521\n",
      "[120]\ttrain-mlogloss:4.1283+0.00327502\ttest-mlogloss:4.18971+0.00560827\n",
      "[121]\ttrain-mlogloss:4.12252+0.00329206\ttest-mlogloss:4.18434+0.00558891\n",
      "[122]\ttrain-mlogloss:4.11674+0.00337142\ttest-mlogloss:4.17912+0.00570981\n",
      "[123]\ttrain-mlogloss:4.11096+0.00344449\ttest-mlogloss:4.1738+0.00568396\n",
      "[124]\ttrain-mlogloss:4.10521+0.00341297\ttest-mlogloss:4.16849+0.00563608\n",
      "[125]\ttrain-mlogloss:4.09952+0.00336066\ttest-mlogloss:4.1632+0.00575089\n",
      "[126]\ttrain-mlogloss:4.09376+0.00340966\ttest-mlogloss:4.15791+0.00576442\n",
      "[127]\ttrain-mlogloss:4.08792+0.00350938\ttest-mlogloss:4.1526+0.00586169\n",
      "[128]\ttrain-mlogloss:4.08218+0.0034453\ttest-mlogloss:4.14734+0.0059033\n",
      "[129]\ttrain-mlogloss:4.07628+0.00353167\ttest-mlogloss:4.14188+0.00591244\n",
      "[130]\ttrain-mlogloss:4.07056+0.00359983\ttest-mlogloss:4.13665+0.00576536\n",
      "[131]\ttrain-mlogloss:4.06468+0.00361525\ttest-mlogloss:4.13118+0.00582874\n",
      "[132]\ttrain-mlogloss:4.05897+0.00360723\ttest-mlogloss:4.1259+0.00588255\n",
      "[133]\ttrain-mlogloss:4.0533+0.00370829\ttest-mlogloss:4.12065+0.00591465\n",
      "[134]\ttrain-mlogloss:4.04755+0.00375741\ttest-mlogloss:4.11536+0.00616655\n",
      "[135]\ttrain-mlogloss:4.04183+0.00364874\ttest-mlogloss:4.11018+0.00629302\n",
      "[136]\ttrain-mlogloss:4.03608+0.00368942\ttest-mlogloss:4.10482+0.00643655\n",
      "[137]\ttrain-mlogloss:4.03036+0.00371878\ttest-mlogloss:4.09958+0.00640562\n",
      "[138]\ttrain-mlogloss:4.02472+0.00389029\ttest-mlogloss:4.09442+0.00655355\n",
      "[139]\ttrain-mlogloss:4.01901+0.00399962\ttest-mlogloss:4.08916+0.00675775\n",
      "[140]\ttrain-mlogloss:4.01343+0.00401609\ttest-mlogloss:4.08402+0.00675715\n",
      "[141]\ttrain-mlogloss:4.00769+0.00394455\ttest-mlogloss:4.07877+0.00680237\n",
      "[142]\ttrain-mlogloss:4.00206+0.00392825\ttest-mlogloss:4.07364+0.00687845\n",
      "[143]\ttrain-mlogloss:3.99629+0.00384941\ttest-mlogloss:4.06837+0.0068956\n",
      "[144]\ttrain-mlogloss:3.99057+0.00384364\ttest-mlogloss:4.06308+0.00695753\n",
      "[145]\ttrain-mlogloss:3.98491+0.00388035\ttest-mlogloss:4.0579+0.00698105\n",
      "[146]\ttrain-mlogloss:3.97922+0.00394466\ttest-mlogloss:4.05267+0.00715293\n",
      "[147]\ttrain-mlogloss:3.97355+0.00396248\ttest-mlogloss:4.04747+0.00716437\n",
      "[148]\ttrain-mlogloss:3.96788+0.00406112\ttest-mlogloss:4.04227+0.00714737\n",
      "[149]\ttrain-mlogloss:3.96209+0.00412599\ttest-mlogloss:4.03691+0.00714135\n",
      "[150]\ttrain-mlogloss:3.95647+0.00417246\ttest-mlogloss:4.03171+0.00721206\n",
      "[151]\ttrain-mlogloss:3.95067+0.00416619\ttest-mlogloss:4.02634+0.00723807\n",
      "[152]\ttrain-mlogloss:3.94507+0.0041045\ttest-mlogloss:4.02116+0.00727204\n",
      "[153]\ttrain-mlogloss:3.9394+0.00406834\ttest-mlogloss:4.01596+0.0072076\n",
      "[154]\ttrain-mlogloss:3.9337+0.00400104\ttest-mlogloss:4.01066+0.00731108\n",
      "[155]\ttrain-mlogloss:3.92795+0.00400227\ttest-mlogloss:4.00534+0.00731053\n",
      "[156]\ttrain-mlogloss:3.92229+0.00413768\ttest-mlogloss:4.0001+0.00738212\n",
      "[157]\ttrain-mlogloss:3.91669+0.00413745\ttest-mlogloss:3.99494+0.00748503\n",
      "[158]\ttrain-mlogloss:3.91115+0.00422215\ttest-mlogloss:3.98985+0.00749976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-acde6fb1afbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cv_results = xgb.cv(params=params, dtrain=xgb_train,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     nfold=5, verbose_eval=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    404\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_results = xgb.cv(params=params, dtrain=xgb_train,\n",
    "                    num_boost_round=1000, early_stopping_rounds=10,\n",
    "                    nfold=5, verbose_eval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:52: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "best_num_round = np.argmin(cv_results['test-%s-mean' % params['eval_metric']])\n",
    "\n",
    "model = xgb.train(params, dtrain=xgb_train, num_boost_round=best_num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005826271186440678"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_pred = model.predict(xgb_test).astype(np.int)\n",
    "accuracy_score(_y_test, _y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5, 116,  18, ..., 116,  54, 111]),\n",
       " array([65, 52, 38, ..., 40, 19, 65]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_pred, _y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,  39,  65, 101,  31,  56,  39,  65,  31, 101, 400, 400])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X_test[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f0': 3886,\n",
       " 'f1': 3644,\n",
       " 'f10': 2187,\n",
       " 'f11': 2456,\n",
       " 'f2': 3394,\n",
       " 'f3': 4451,\n",
       " 'f4': 8753,\n",
       " 'f5': 4269,\n",
       " 'f6': 3998,\n",
       " 'f7': 3827,\n",
       " 'f8': 4336,\n",
       " 'f9': 7765}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_meta framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "CV_SPLIT = StratifiedKFold(n_splits=5, shuffle=True, random_state=555)\n",
    "MODEL = Pipeline\n",
    "SCORINGS = [\"neg_log_loss\", \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "scorings = SCORINGS\n",
    "cv = CV_SPLIT\n",
    "estimator_cls = MODEL\n",
    "model_params = {\n",
    "    \"steps\": [\n",
    "        (\"scaler\", StandardScaler),\n",
    "        (\"log_reg\", LogisticRegression)\n",
    "    ]\n",
    "}\n",
    "model_hp_params = {\n",
    "    \"log_reg\": {\n",
    "        \"C\": hp.loguniform(\"C\", 0, 4),\n",
    "        \"random_state\": hp.randint(\"random_state\", 12345)\n",
    "    }\n",
    "}\n",
    "model_hp_params.update(model_params)\n",
    "fit_params = {}\n",
    "n_jobs = 10\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def hp_score(model_hp_params):\n",
    "    if estimator_cls == Pipeline:\n",
    "        steps=model_hp_params['steps']\n",
    "        nsteps = []\n",
    "        for name, fn in steps:\n",
    "            nsteps.append((name, fn(**model_hp_params[name]) if name in model_hp_params else fn()))\n",
    "        estimator = estimator_cls(steps=nsteps)\n",
    "    else:\n",
    "        estimator = estimator_cls(**model_hp_params)\n",
    "\n",
    "    scores = cross_validate(estimator, _X, _y, cv=cv, scoring=scorings,\n",
    "                            fit_params=fit_params, \n",
    "                            return_train_score=True,\n",
    "                            n_jobs=n_jobs, verbose=debug)\n",
    "\n",
    "    print(\"CV scores:\")\n",
    "    for scoring in scorings:\n",
    "        print(\"{} : \\n\\t train: {} \\n\\t test: {}\".format(scoring, \n",
    "                                                   scores[\"train_{}\".format(scoring)].tolist(),\n",
    "                                                   scores[\"test_{}\".format(scoring)].tolist()))\n",
    "\n",
    "    mean_test_loss = np.abs(np.mean(scores[\"test_{}\".format(scorings[0])]))\n",
    "    return {\n",
    "        'loss': mean_test_loss,\n",
    "        'status': STATUS_OK\n",
    "    }\n",
    "\n",
    "\n",
    "def hp_optimize(score_fn, params_space, max_evals):\n",
    "    trials = Trials()\n",
    "    best_params = fmin(score_fn, params_space, algo=tpe.suggest, trials=trials, max_evals=max_evals, verbose=debug)\n",
    "    return best_params, trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5480578202532933, -3.573541458420192, -3.556483475390815, -3.5734635082382846, -3.559566390562097] \n",
      "\t test: [-3.876761071432662, -3.7987699002087667, -3.861823010894172, -3.8203330980363828, -3.856333740654891]\n",
      "accuracy : \n",
      "\t train: [0.21692276990620635, 0.21612452604270604, 0.2190988835725678, 0.22164948453608246, 0.21369539551357733] \n",
      "\t test: [0.15546875, 0.17109375, 0.15137254901960784, 0.15717722534081796, 0.16708023159636062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5335622329113594, -3.560580454612384, -3.543369753758897, -3.559195938468275, -3.5462211255181173] \n",
      "\t test: [-3.8788090871378316, -3.7920604390463724, -3.8588589626925316, -3.8285753684615313, -3.8568271982794786]\n",
      "accuracy : \n",
      "\t train: [0.21951706246258232, 0.21971662342845738, 0.22149122807017543, 0.22620935765265662, 0.2170405352223534] \n",
      "\t test: [0.15390625, 0.175, 0.15294117647058825, 0.16038492381716118, 0.16790736145574855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5335107548027653, -3.560536443855174, -3.543325165563332, -3.5591428628079376, -3.5461749022047337] \n",
      "\t test: [-3.8787994822713303, -3.792036417279269, -3.8588529614396476, -3.8286617195329233, -3.856841095793991]\n",
      "accuracy : \n",
      "\t train: [0.21951706246258232, 0.21971662342845738, 0.22169059011164274, 0.22620935765265662, 0.2170405352223534] \n",
      "\t test: [0.15390625, 0.175, 0.15294117647058825, 0.16038492381716118, 0.16790736145574855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5301695480330655, -3.5577411073066374, -3.5405150856591243, -3.555634485038779, -3.543262366624294] \n",
      "\t test: [-3.878288170768221, -3.7906628162536706, -3.858487046629541, -3.836962701899376, -3.8580629924731498]\n",
      "accuracy : \n",
      "\t train: [0.22031530632608262, 0.22051486729195768, 0.22208931419457736, 0.22759714512291832, 0.21881149153876425] \n",
      "\t test: [0.15390625, 0.17578125, 0.15372549019607842, 0.161186848436247, 0.1687344913151365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.6412149405083256, -3.6623541350780595, -3.647051159054922, -3.6636754148795325, -3.649798346226116] \n",
      "\t test: [-3.910411087285746, -3.8537241934283726, -3.9015714957865724, -3.8591563945811527, -3.8921377188584545]\n",
      "accuracy : \n",
      "\t train: [0.2021552584314508, 0.19976052684094991, 0.2031499202551834, 0.20796986518636004, 0.20070838252656434] \n",
      "\t test: [0.14609375, 0.15703125, 0.1419607843137255, 0.14194065757818766, 0.1555004135649297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5418475465750525, -3.5678841565703174, -3.550749534889018, -3.567418335967986, -3.5537636996286] \n",
      "\t test: [-3.877359549333575, -3.7957722507117437, -3.8603290674897295, -3.821554630797394, -3.855913665578232]\n",
      "accuracy : \n",
      "\t train: [0.21772101376970665, 0.2179205747355817, 0.2204944178628389, 0.22303727200634418, 0.2154663518299882] \n",
      "\t test: [0.15390625, 0.171875, 0.15058823529411763, 0.15797914995990378, 0.16708023159636062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5302253370252634, -3.557786554505024, -3.5405603840559934, -3.555695370667215, -3.543309809502242] \n",
      "\t test: [-3.878294492633208, -3.7906850542229513, -3.858491684502919, -3.8367612337592343, -3.8580357675958092]\n",
      "accuracy : \n",
      "\t train: [0.22051486729195768, 0.22051486729195768, 0.22208931419457736, 0.22759714512291832, 0.21861471861471862] \n",
      "\t test: [0.15390625, 0.17578125, 0.15372549019607842, 0.161186848436247, 0.1687344913151365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.530103692287255, -3.557686402848865, -3.5404602807250956, -3.555561235270802, -3.543205117480558] \n",
      "\t test: [-3.8782802025325758, -3.790635995336726, -3.858481555953372, -3.837212224952376, -3.858094539802838]\n",
      "accuracy : \n",
      "\t train: [0.22031530632608262, 0.22051486729195768, 0.22208931419457736, 0.22759714512291832, 0.21861471861471862] \n",
      "\t test: [0.15390625, 0.17578125, 0.15372549019607842, 0.161186848436247, 0.1687344913151365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.5328783101332215, -3.559998474759919, -3.542783448043214, -3.558495327145858, -3.5456159604034503] \n",
      "\t test: [-3.8786859094869968, -3.791770079503877, -3.858772218786317, -3.8297887195309777, -3.8570205853319]\n",
      "accuracy : \n",
      "\t train: [0.21971662342845738, 0.21991618439433247, 0.22188995215311005, 0.22660586835844568, 0.21802439984258165] \n",
      "\t test: [0.15390625, 0.175, 0.15294117647058825, 0.16038492381716118, 0.16790736145574855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-3.53383311165198, -3.5608121551076777, -3.5436031694436383, -3.5594717026322664, -3.546461708470491] \n",
      "\t test: [-3.8788592191898728, -3.7921754444658866, -3.858895201865167, -3.828140446035383, -3.8567572498683806]\n",
      "accuracy : \n",
      "\t train: [0.21931750149670726, 0.21971662342845738, 0.22129186602870812, 0.22620935765265662, 0.2170405352223534] \n",
      "\t test: [0.15390625, 0.17421875, 0.15294117647058825, 0.1595829991980754, 0.16790736145574855]\n",
      "Best parameters: \n",
      "{'steps': [('scaler', <class 'sklearn.preprocessing.data.StandardScaler'>), ('log_reg', <class 'sklearn.linear_model.logistic.LogisticRegression'>)], 'random_state': 7824, 'C': 10.739394454022523}\n",
      "Best trial : \n",
      "{'result': {'status': 'ok', 'loss': 3.8421858327821345}, 'exp_key': None, 'owner': None, 'state': 2, 'tid': 5, 'misc': {'tid': 5, 'idxs': {'random_state': [5], 'C': [5]}, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'vals': {'random_state': [7824], 'C': [10.739394454022523]}, 'workdir': None}, 'version': 0, 'book_time': datetime.datetime(2018, 4, 28, 21, 42, 26, 806000), 'spec': None, 'refresh_time': datetime.datetime(2018, 4, 28, 21, 42, 30, 604000)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 out of   5 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "best_params, trials = hp_optimize(hp_score, model_hp_params, max_evals=n_trials)\n",
    "best_params.update(model_params)\n",
    "\n",
    "print(\"Best parameters: \\n{}\".format(best_params))\n",
    "print(\"Best trial : \\n{}\".format(trials.best_trial))\n",
    "\n",
    "# print(\"Train meta model on complete dataset\")\n",
    "# estimator = estimator_cls(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.739394454022523,\n",
       " 'random_state': 7824,\n",
       " 'steps': [('scaler', sklearn.preprocessing.data.StandardScaler),\n",
       "  ('log_reg', sklearn.linear_model.logistic.LogisticRegression)]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.update(model_params)\n",
    "estimator = estimator_cls(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "CV_SPLIT = StratifiedKFold(n_splits=5, shuffle=True, random_state=555)\n",
    "MODEL = CatBoostClassifier\n",
    "SCORINGS = [\"neg_log_loss\", ] #\"precision_macro\", \"recall_macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 2\n",
    "scorings = SCORINGS\n",
    "cv = CV_SPLIT\n",
    "estimator_cls = MODEL\n",
    "model_params = {\n",
    "    \"iterations\": 5,\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"od_wait\": 50,\n",
    "    \"bootstrap_type\": \"Bernoulli\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"verbose\": True,\n",
    "    \"metric_period\": 1\n",
    "}\n",
    "model_hp_params = {\n",
    "    \"depth\": 2 + hp.randint(\"depth\", 5),\n",
    "    \"learning_rate\": hp.quniform(\"learning_rate\", 0.001, 0.5, 0.005),\n",
    "    \"l2_leaf_reg\": 2 + hp.randint(\"l2_leaf_reg\", 2),\n",
    "    \"random_seed\": hp.randint(\"random_seed\", 12345),\n",
    "    \"subsample\": hp.quniform(\"subsample\", 0.5, 1.0, 0.01)\n",
    "}\n",
    "model_hp_params.update(model_params)\n",
    "fit_params = {}\n",
    "n_jobs = 10\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = X.values\n",
    "_y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def hp_score(model_hp_params):\n",
    "    \n",
    "    estimator = estimator_cls(**model_hp_params)\n",
    "\n",
    "    scores = cross_validate(estimator, _X, _y, cv=cv, scoring=scorings,\n",
    "                            fit_params=fit_params,\n",
    "                            return_train_score=True,                            \n",
    "                            n_jobs=n_jobs)\n",
    "\n",
    "    print(\"CV scores:\")\n",
    "    for scoring in scorings:\n",
    "        print(\"{} : \\n\\t train: {} \\n\\t test: {}\".format(scoring, \n",
    "                                                   scores[\"train_{}\".format(scoring)].tolist(),\n",
    "                                                   scores[\"test_{}\".format(scoring)].tolist()))\n",
    "\n",
    "    mean_test_loss = np.abs(np.mean(scores[\"test_{}\".format(scoring)]))\n",
    "    return {\n",
    "        'loss': mean_test_loss,\n",
    "        'status': STATUS_OK\n",
    "    }\n",
    "\n",
    "\n",
    "def hp_optimize(score_fn, params_space, max_evals):\n",
    "    trials = Trials()\n",
    "    best_params = fmin(score_fn, params_space, algo=tpe.suggest, trials=trials, max_evals=max_evals, verbose=debug)\n",
    "    return best_params, trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -4.7117042\ttotal: 20.6s\tremaining: 1m 22s\n",
      "0:\tlearn: -4.7280812\ttotal: 20.7s\tremaining: 1m 22s\n",
      "0:\tlearn: -4.7249822\ttotal: 20.9s\tremaining: 1m 23s\n",
      "0:\tlearn: -4.6774325\ttotal: 22.2s\tremaining: 1m 28s\n",
      "0:\tlearn: -4.7068981\ttotal: 23.7s\tremaining: 1m 34s\n",
      "1:\tlearn: -4.5168791\ttotal: 41.5s\tremaining: 1m 2s\n",
      "1:\tlearn: -4.5250657\ttotal: 41.7s\tremaining: 1m 2s\n",
      "1:\tlearn: -4.6246349\ttotal: 41.8s\tremaining: 1m 2s\n",
      "1:\tlearn: -4.6276355\ttotal: 42.6s\tremaining: 1m 3s\n",
      "1:\tlearn: -4.5363106\ttotal: 46.8s\tremaining: 1m 10s\n",
      "2:\tlearn: -4.4961720\ttotal: 1m 2s\tremaining: 41.9s\n",
      "2:\tlearn: -4.3414154\ttotal: 1m 3s\tremaining: 42.2s\n",
      "2:\tlearn: -4.4109650\ttotal: 1m 3s\tremaining: 42.3s\n",
      "2:\tlearn: -4.4711836\ttotal: 1m 5s\tremaining: 43.8s\n",
      "2:\tlearn: -4.4313898\ttotal: 1m 7s\tremaining: 44.9s\n",
      "3:\tlearn: -4.3371345\ttotal: 1m 24s\tremaining: 21s\n",
      "3:\tlearn: -4.3623223\ttotal: 1m 25s\tremaining: 21.3s\n",
      "3:\tlearn: -4.2483936\ttotal: 1m 26s\tremaining: 21.6s\n",
      "3:\tlearn: -4.3404164\ttotal: 1m 27s\tremaining: 21.8s\n",
      "3:\tlearn: -4.2623334\ttotal: 1m 28s\tremaining: 22.2s\n",
      "4:\tlearn: -4.2955514\ttotal: 1m 46s\tremaining: 0us\n",
      "4:\tlearn: -4.2300309\ttotal: 1m 47s\tremaining: 0us\n",
      "4:\tlearn: -4.2237970\ttotal: 1m 47s\tremaining: 0us\n",
      "4:\tlearn: -4.1754108\ttotal: 1m 47s\tremaining: 0us\n",
      "4:\tlearn: -4.1793533\ttotal: 1m 47s\tremaining: 0us\n",
      "CV scores:\n",
      "neg_log_loss : \n",
      "\t train: [-4.230030944644081, -4.2237969963568265, -4.295551363333924, -4.179353263800418, -4.175410806600211] \n",
      "\t test: [-4.25157665135408, -4.231374858290454, -4.305536161939012, -4.183279148082734, -4.195846683771765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-477:\n",
      "Process ForkPoolWorker-476:\n",
      "Process ForkPoolWorker-478:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-480:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-479:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-e83826ef7155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_hp_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters: \\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best trial : \\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-808ea67c3bd4>\u001b[0m in \u001b[0;36mhp_optimize\u001b[0;34m(score_fn, params_space, max_evals)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhp_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-808ea67c3bd4>\u001b[0m in \u001b[0;36mhp_score\u001b[0;34m(model_hp_params)\u001b[0m\n\u001b[1;32m      8\u001b[0m                             \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                             \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                             n_jobs=n_jobs)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CV scores:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params, trials = hp_optimize(hp_score, model_hp_params, max_evals=n_trials)\n",
    "best_params.update(model_params)\n",
    "\n",
    "print(\"Best parameters: \\n{}\".format(best_params))\n",
    "print(\"Best trial : \\n{}\".format(trials.best_trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
